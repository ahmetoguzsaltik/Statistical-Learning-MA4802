{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzmXO2mQR6M4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import scipy.special as sspecial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qhx5SlL5R6NI"
   },
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQD1znMgR6NK"
   },
   "source": [
    "Maximize the likelihood. You can define $\\theta_i =                          \n",
    "\\text{sigm}(x_i^T \\beta)$ for this. Why can the resulting equations\n",
    "not be solved in closed form for the parameters $\\beta$ (as in\n",
    "linear regression), but are suitable for iterative methods?\n",
    "\n",
    "From the definition of the Bernulli distribution we get\n",
    "\\begin{align}\n",
    "L(\\theta) = \\prod_{i=1}^N \\theta_{i}^{y_i} (1 - \\theta_2)^{1-y_i} \\\\\n",
    "l(\\theta) =  \\sum_{i=1}^N y_i \\log \\theta_{i} + (1 - y_{i}) \\log (1 - \\theta_{i})\\\\\n",
    "\\end{align}\n",
    "therefor,\n",
    "\n",
    "\\begin{align}\n",
    "l(\\beta) \n",
    "& = \\sum_{i=1}^N \\log \\left(\\theta_i^{\\mathbb{I}(y_i=1)}(1-\\theta_i)^{\\mathbb{I}(y_i=0)} \\right) \\\\\n",
    "& = \\sum_{i=1}^N y_i \\log \\theta_i + (1-y_i) \\log (1-\\theta_i) \n",
    "&= l_1(\\beta)+l_2(\\beta)\n",
    "\\end{align}\n",
    "\n",
    "if we define $l_1(\\beta)= \\sum_{i=1}^N y_i \\log \\theta_i$ and  $l_2(\\beta) = \\sum_{i=1}^N  (1-y_i) \\log (1-\\theta_i) $ we can further maximize the function using $\\log(\\theta) = - \\log(1 + e^{-X^T \\beta})$\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{d \\log(\\theta_i)}{d \\log \\beta_n} \n",
    "& = - \\frac{1}{1+e^{-X^T \\beta} } \\cdot e^{-X^T \\beta} \\cdot  - (x_{xn}) \\\\\n",
    "& = (1-\\theta) x_{in}\\\\ \n",
    "\\end{align}\n",
    "\n",
    "so we get $\\frac{d}{d\\beta_n} \\log \\theta_i = (1-\\theta_i) x_{in}$ following the same steps we can also derive $\\frac{d}{d\\beta_n}\\log(1-\\theta_i) = -\\theta_i x_{in}$\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{d l(\\beta)}{d \\beta_n} = \n",
    "\\frac{d l_1(\\beta)}{d \\log (\\theta_i)} \\cdot \\frac{d \\log(\\theta_i)}{d \\beta_n}+ \\frac{d l_2(\\beta)}{d \\log (1-\\theta_i)} \\cdot \\frac{d \\log(1- \\theta_i)}{d \\beta_n}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "& =  \\sum_{I} y_i (1- \\theta_{i}) x_{in} + (1 - y_{i})  (-\\theta_{i}x_{in}) = \\\\\n",
    "& =  \\sum_{I} (y_i- \\theta_{i}) x_{in}  = \\pmb{X}^T (\\pmb{y} - \\pmb{\\theta})  \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Evidently solving $\\frac{d}{d\\beta_n} l(\\beta) = 0$ for $\\beta$ is not possible in closed form. The Hessian (obtained as $H_{nm} = \\frac{d}{d\\beta_n} \\frac{d}{d\\beta_m} l(\\beta)$), which is given on the sheet though\n",
    "$$\n",
    "\\pmb{H} = - \\sum_i \\theta_i (1-\\theta_i) x_i x_i^T\n",
    "$$\n",
    "is negative definite. To show this, consider multiplying with a vector $u\\in \\mathbb{R}^{p+1}$ from left and the right\n",
    "\n",
    "$$\n",
    "u^T \\pmb{H} u = - \\sum_i \\theta_i (1-\\theta_i) (x_i^T u)^2 \\leq 0\n",
    "$$\n",
    "\n",
    "As $\\theta_i \\in (0,1)$ equality only holds if $u=0$ or if $u$ is in the null space (kernel) of $\\pmb{X}$, that is perpendicular to all vectors $x_i$. It is extremely unlikely that such a vector exists in $\\mathbb{R}^{p+1}$ as soon as $N \\gg p + 1$. Then $\\pmb{H}$ is strictly negative definite, $l(\\beta)$ therefore concave, and $-l(\\beta)$ therefore convex with a unique minimum that can easily be found with standard iterative search algorithms (Newton-Raphson, BFGS). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9uHHLYykSFrA"
   },
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28572,
     "status": "ok",
     "timestamp": 1591089048232,
     "user": {
      "displayName": "彭廷莹",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-TVZvcFXv_ddQnFSonh6P-VF0zYaqOPEA1p_l=s64",
      "userId": "00488430844757231586"
     },
     "user_tz": -120
    },
    "id": "IL_V42RqSqgo",
    "outputId": "ef467c63-d6d2-46c9-8dcf-0162bddaaaae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "[Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/statisticallearning-2020/Sheet06/solution'\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1591089109058,
     "user": {
      "displayName": "彭廷莹",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-TVZvcFXv_ddQnFSonh6P-VF0zYaqOPEA1p_l=s64",
      "userId": "00488430844757231586"
     },
     "user_tz": -120
    },
    "id": "8aXb82pUTIE2",
    "outputId": "360b01e4-b7c4-40ea-fd37-8b307968cb22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/statisticallearning-2020/Sheet06/Solution\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/Colab Notebooks/statisticallearning-2020/Sheet06/Solution'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1TS6Eq_R6NM"
   },
   "outputs": [],
   "source": [
    "def likelihood_ratio_test(LLF_full,LLF_reduced,df):\n",
    "    D = -2*(LLF_reduced-LLF_full)\n",
    "    p = sspecial.gammaincc(df/2,D/2)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 742,
     "status": "ok",
     "timestamp": 1591089123987,
     "user": {
      "displayName": "彭廷莹",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-TVZvcFXv_ddQnFSonh6P-VF0zYaqOPEA1p_l=s64",
      "userId": "00488430844757231586"
     },
     "user_tz": -120
    },
    "id": "3NK4vWhfR6NZ",
    "outputId": "e19ca7ea-7b0a-4b1a-a491-eb950ff3b47d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  age  chd\n",
       "0  160    12.00  5.73      23.11        1     49    25.30    97.20   52    1\n",
       "1  144     0.01  4.41      28.61        0     55    28.87     2.06   63    1\n",
       "2  118     0.08  3.48      32.28        1     52    29.14     3.81   46    0\n",
       "3  170     7.50  6.41      38.03        1     51    31.99    24.26   58    1\n",
       "4  134    13.60  3.50      27.78        1     60    25.99    57.34   49    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data to play with\n",
    "SAheart = pd.read_csv('SAheart.csv',delimiter=',')\n",
    "SAheart.head(5)\n",
    "famhist = {'Present': 1,'Absent': 0} \n",
    "# traversing through dataframe \n",
    "# famhist column and writing \n",
    "# values where key matches\n",
    "SAheart.famhist = [famhist[item] for item in SAheart.famhist] \n",
    "\n",
    "X = SAheart.values[:,0:9] \n",
    "y = np.array(SAheart.values[:,9])\n",
    "y=y.astype('int')\n",
    "feature_name= list(SAheart)\n",
    "SAheart.head(5)\n",
    "# feature_name = ['sbp','tobacco','Idl','adiposity','famhist','typea','obsesity','alcohol','age']\n",
    "\n",
    "# logreg_null = linear_model.LogisticRegression(C=1e6,solver='newton-cg',intercept_scaling=1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nNxNDlzR6Nm"
   },
   "outputs": [],
   "source": [
    "# we fit the null model.\n",
    "from sklearn import linear_model,preprocessing\n",
    "logreg_null = linear_model.LogisticRegression(C=1e6,solver='newton-cg',intercept_scaling=1e3)\n",
    "logreg_null.fit(np.zeros(y.size).reshape(-1,1), y)\n",
    "prob_pi = logreg_null.predict_proba(np.zeros(y.size).reshape(-1,1))[:,1]\n",
    "LLF_null = (y*np.log(prob_pi)).sum()+((1.0-y)*np.log(1.0-prob_pi)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAL0y2WQR6Nv"
   },
   "outputs": [],
   "source": [
    "# we fit the single feature model.\n",
    "logreg_sf=linear_model.LogisticRegression(C=1e6,solver='newton-cg',intercept_scaling=1e3)\n",
    "LLF_sf = np.zeros(X.shape[1])\n",
    "LRT_sf = np.zeros(X.shape[1])\n",
    "for i in range(X.shape[1]): \n",
    "    logreg_sf.fit(X[:,i].reshape(-1,1),y)\n",
    "    prob_pi=logreg_sf.predict_proba(X[:,i].reshape(-1,1))[:,1]\n",
    "    LLF_sf[i]= (y*np.log(prob_pi)).sum()+((1.0-y)*np.log(1.0-prob_pi)).sum()\n",
    "    LRT_sf[i] = likelihood_ratio_test(LLF_sf[i],LLF_null,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 641,
     "status": "ok",
     "timestamp": 1591089160699,
     "user": {
      "displayName": "彭廷莹",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-TVZvcFXv_ddQnFSonh6P-VF0zYaqOPEA1p_l=s64",
      "userId": "00488430844757231586"
     },
     "user_tz": -120
    },
    "id": "ffqo_SiFR6N2",
    "outputId": "a66f39af-c32c-4397-dcd6-9100e43e1366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelyhood selected features:\n",
      "\n",
      "intercept: -4.11859447082756 \n",
      "\n",
      "age : 0.046455844051662726 \n",
      "\n",
      "tobacco : 0.08084889737557976 \n",
      "\n",
      "famhist : 0.9258628837328553 \n",
      "\n",
      "ldl : 0.17759533500231234 \n",
      "\n",
      "adiposity : -0.009298203673909138 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# feature selection by adding one additional feature at a time.\n",
    "feature_sidx = np.argsort(LRT_sf) # sort feature according to its significance (low to high)\n",
    "logreg_mf= linear_model.LogisticRegression(C=1e6,solver='newton-cg',intercept_scaling=1e3)\n",
    "logreg_mf.fit(X[:,feature_sidx[0]].reshape(-1,1),y)\n",
    "prob_pi = logreg_mf.predict_proba(X[:,feature_sidx[0]].reshape(-1,1))[:,1]\n",
    "LLF_old = (y*np.log(prob_pi)).sum()+((1.0-y)*np.log(1.0-prob_pi)).sum()\n",
    "for i in range(X.shape[1]-1):\n",
    "    X_mf = X[:,(feature_sidx[0:i+2])]\n",
    "    logreg_mf.fit(X_mf,y)\n",
    "    prob_pi = logreg_mf.predict_proba(X_mf)[:,1]\n",
    "    LLF_new = (y*np.log(prob_pi)).sum()+((1.0-y)*np.log(1.0-prob_pi)).sum()\n",
    "    LRF_mf = likelihood_ratio_test(LLF_new,LLF_old,1)\n",
    "    if LRF_mf>0.05:\n",
    "        break\n",
    "    else:\n",
    "        LLF_old = LLF_new\n",
    "\n",
    "# print selected features and their coefficients      \n",
    "print(\"Likelyhood selected features:\\n\")\n",
    "print(\"intercept:\",logreg_mf.intercept_[0],\"\\n\")\n",
    "for i in range(logreg_mf.coef_.size):\n",
    "    print(feature_name[feature_sidx[i]],\":\", logreg_mf.coef_.flatten()[i],\"\\n\")         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 494,
     "status": "ok",
     "timestamp": 1591089322676,
     "user": {
      "displayName": "彭廷莹",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-TVZvcFXv_ddQnFSonh6P-VF0zYaqOPEA1p_l=s64",
      "userId": "00488430844757231586"
     },
     "user_tz": -120
    },
    "id": "roxAlCWbR6N9",
    "outputId": "bd15d9ac-3509-44e3-e74f-8d8590922f3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 selected features:\n",
      "\n",
      "intercept: -0.72831740590086 \n",
      "\n",
      "age : 0.479245188340632 \n",
      "\n",
      "famhist : 0.25685762582182736 \n",
      "\n",
      "tobacco : 0.20951222669388234 \n",
      "\n",
      "ldl : 0.1761288030464226 \n",
      "\n",
      "typea : 0.07065183229701169 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use l1 norm to select features\n",
    "# note the features must be normalised first\n",
    "X_scaled = preprocessing.scale(X)  \n",
    "logreg_l1 = linear_model.LogisticRegression(C=0.05,intercept_scaling=1e3,penalty='l1',solver='liblinear')\n",
    "logreg_l1.fit(X_scaled,y)    \n",
    "# print selected features and their coefficients   \n",
    "feature_sidx2 = np.argsort(np.abs(logreg_l1.coef_.flatten()))\n",
    "feature_sidx2 = feature_sidx2[::-1]   \n",
    "print(\"L1 selected features:\\n\")\n",
    "print(\"intercept:\",logreg_l1.intercept_[0],\"\\n\")\n",
    "for i in range(logreg_l1.coef_.size):\n",
    "    coef = logreg_l1.coef_.flatten()[feature_sidx2[i]]\n",
    "    if np.abs(coef)>1e-5:\n",
    "        print(feature_name[feature_sidx2[i]],\":\", coef,\"\\n\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_MouVJ0lR6OC"
   },
   "source": [
    "Logistic regression with lasso regularization is a powerful method for feature selection, as only selected features have a non-zero coefficient. This is much simpler than the iterative model comparison with likelyhood calculation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apHKbSI3R6OD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sheet06_PySol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
